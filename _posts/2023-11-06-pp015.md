---
title: "pp015.Grok & DeepseekCoder"
style: post
tags: paper llm 
---

AI前沿｜近期值得关注的两个模型：Grok与DeepseekCoder

1. xAI发布Grok

这个训了俩月的模型Grok被设计于带着一点智慧地回答问题，且有点叛逆。其拥有一个独特的优势是它通过𝕏平台实时了解世界。还能回答大多数其他人工智能系统拒绝的尖锐问题。加持Grok的具体模型是Grok-1，一个自回归式的基于transformer的模型。xAI宣布成立后他们先训了一个33B参数的原型LLM Grok-0，该模型用一半的训练资源就在各种语言模型榜单上达到了像LLaMA 2（70B）这种规模模型的能力。接着在上两个月，xAI在模型上大幅提升推理和代码能力，训出了Grok-1，其在HumanEval上达到63.2%，在MMLU上达到73%。在其他各榜单上的效果见下图。在这些榜单上Grok-1超过了包括ChatGPT-3.5和Inflection-1。不过这些榜单在网上都有，可能被泄露了，作者就手动测了一下今年5月份匈牙利国家高中数学考试，结果如下，Grok-1还是很强的。

该模型的总结可以看Grok-1的model card。

2. DeepSeek Coder

DeepSeek Coder是由幻方DeepSeek AI发布的一系列代码语言模型，从头开始在87%比例代码、13%比例英语和中文共2T token的数据上训练的。模型规模小有1.3B, 5.7B, 6.7B和33B。每个模型都在代码库级别的语料上训练，上下文长度16k且有额外的填空任务（应该类似FIM），基座模型叫DeepSeek-Coder-Base，并在此基座上用2B指令数据训出一个指令微调模型，即DeepSeek-Coder-Instruct。他们的模型开源且对免费研究与商用免费。

强大的模型表现如下图，结果显示，DeepSeek-Coder-Base-33B性能显著优于现有的开源代码LLM。与CodeLLama-34B相比，在HumanEval Python、HumanEval Multilingual、MBPP和DS-1000上分别领先7.9%、9.3%、10.8%和5.9%。 而且，DeepSeek-Coder-Base-7B达到了CodeLlama-34B的效果。 指令调优后的DeepSeek-Coder-Instruct-33B模型在HumanEval上的表现优于GPT-3.5-turbo，并在MBPP上达到与GPT-3.5-turbo相当的结果。

另外，从实际试用的感觉来看，这个DeepSeek Coder确实强，不愧是有某代码模型领域的新星参与的项目。
