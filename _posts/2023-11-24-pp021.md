---
title: "pp021.GAIA: A Benchmark for General AI Assistants"
style: post
tags: paper llm 
---

AI｜GAIA：据说解决了这个基准，AI研究又会达到一个里程碑（作者自己说的

该论文介绍了GAIA，一个用于测试通用人工智能助手（General AI Assistants）的基准，作者声称如果解决了，将代表AI研究的一个里程碑。GAIA提出了一系列现实世界中的问题，这些问题需要一组基本的能力，如推理、多模态处理、网页浏览和熟练地使用通用工具。对于人类而言，GAIA的问题在概念上相对简单，但对大多数先进的AI而言却具有挑战性：作者对比了人类与配备插件的GPT-4的回答，正确率分别为92%和15%。这一显著的性能差异与最近LLM在需要专业技能（如法律或化学）的任务中优于人类的趋势形成对比。GAIA的理念与当前AI基准测试的趋势不同，后者倾向于针对对人类而言变得更加困难的任务。作者认为，AGI的出现取决于系统在这类问题上表现出与普通人类相似的鲁棒性。使用GAIA的方法，作者设计了466个问题及其答案。他们公开了这些问题，并保留了其中300个问题的答案，以便形成一个可访问的排行。

在寻找更具挑战性的基准方面，当前趋势是寻找对人类来说越来越难的任务，并通过更复杂的教育评估LLM，如在STEM和法律领域，或追求更复杂的实现，如写一本连贯的书。但，对人类而言困难的任务并不一定对最新的系统而言困难：例如，具有挑战性的MMLU或GSM8k由于LLM的迅速改进与可能的数据污染而已经接近解决。此外，开放式生成通常需要人类或基于模型的评估。随着任务复杂性增加，如输出长度或所需技能方面，人类评估将变得越发不可行，比如如何评估由AI生成的书籍或解决少有人能做的数学题？另一方面，基于模型的评估依赖于更强的模型上，因此不能评估新的最先进模型，更别提潜在的微妙偏见（如模型倾向于选择呈现的第一个选择）。总之，重新思考基准测试很重要。
与对人类而言更难的任务相反，可以要求AI系统解决在概念上简单但需要准确执行复杂动作序列、具有大量组合空间的任务。这种任务的输出只能在成功完成任务后获得，并且易于验证。鉴于AI需要访问多样且不确定的世界，这些任务满足这一标准，并且根植于实际用例。作者提出的GAIA就满足上述要求，其中包括466个精心设计的问题及其答案，以及相关的设计方法。这些问题易于创建，对AI系统而言具有挑战性，对LLM而言，大多数都要进行复杂的生成，但只允许一个独特且符合事实性的答案，从而实现简单而强大的自动评估。例子见figure1和figuare2，看了就理解大概是什么样子的题目了，figure1中的难度等级解释如下：

- Level 1：问题通常无需任何工具，或者最多需要一个工具，但步骤不超过5步。
- Level 2：问题通常涉及更多步骤，大致在5到10步之间，并需结合不同的工具。
- Level 3：问题适用于近乎完美的通用助手，需要执行任意长的操作序列，使用任意数量的工具，并能够访问整个世界。

GAIA试图避免当下评估的问题，具体体现在：
- 针对现实且具有挑战性的问题。如模型通常需要浏览开放且不断变化的网络，处理多模态或在多个步骤上进行推理，以回答问题。
- 通过概念上简单的任务实现易解释性，关联上一些推理步骤和少但精心构造的问题。
- 不易被操纵。回答问题需完成一定数量的步骤，由于其多样性，这些步骤不易通过蛮力破解。检查推理过程、答案准确性以及它们在互联网纯文本中的缺失防止了可能的数据污染。
- 使用简易性。答案是易于验证、简洁而明确的事实性答案，这使得评估简单、快速且具有事实性。作者将问题限制在零样本模式下回答，消除不同评估设置的影响。

figure3展示了测试集的分析，需要哪些能力，以及需要多少不同的工具解决问题。figure4展示了LLM、人类和搜索引擎在GAIA上的效果。
