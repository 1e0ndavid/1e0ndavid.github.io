---
title: "pp008.LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS"
style: post
tags: paper llm prompting_method reasoning
---

AI前沿｜类比提示：简单却有效的提示技巧，增强模型复杂任务能力

CoT提示技术在各种推理任务上有很好表现但通常其需要对推理过程做标注。在这个工作中作者介绍了新的提示方法：analogical（类比） prompting，设计用于自动化指导模型推理。该方法受人类从过去的相关经验中汲取经验来解决新问题这一认知过程启发，促使语言模型在解决给定问题前在上下文中自行生成相关的范例或知识。该方法具有以下优点：无需标记或检索示例，通用且便利；它还可以针对每个问题定制生成的示例和知识，极具适应性。实验结果表明，该方法在各种推理任务中都优于零样本CoT和手动的少样本CoT，包括在GSM8K和MATH中的数学问题、Codeforces中的代码生成及BIG-Bench中的其他推理任务。

关于类比提示的例子见figure1，当面对一个新的数学问题（如，在给定坐标系下四个点后求出正方形面积），人类通常会想“我是否知道相关问题？”并回忆起他们在过去如何解决相关问题（如在已知变长的时候下怎么求正方形面积的）来获取解决新问题的灵感。他们也回忆起高阶知识，比如需要找到边长来计算正方形的面积。作者的想法是促使LLM模仿该推理过程，以有效解决新问题。

具体而言，给定问题，作者提示LLM在上下文中自生成相关案例，使用例如“# Recall relevant problems and solutions:...”的指令，然后进一步解决原问题（见figure1、2）。同时，作者也用类似“# Provide a tutorial:...”的指令提示模型来生成高阶知识以补充具体样例。这对于代码生成特别有用，值得注意的是，该方法可以在单个提示下只过一轮边端到端地生成知识、示例和初始问题的解答。其底层思想在于现代LLM已经在训练时掌握了各种底层问题的知识。显性提示以使得模型回忆起相关问题与接发，让模型在上下文学习中解出新问题。

该方法的优点：它自行生成样本，无需为每个任务手动标记推理样本，解决了零样本和少样本CoT面临的挑战。此外，自我生成的样本是针对问题量身定制的，例如“几何”或“概率”，而非一般的“数学问题”。这简化了CoT技术从外部数据检索相关样本的复杂性。

该方法在各种复杂任务上的表现见table1、2、3
